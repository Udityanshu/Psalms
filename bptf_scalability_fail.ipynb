{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rn\n",
    "import sktensor as skt\n",
    "\n",
    "import pickle\n",
    "#from path import path\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def is_binary(X):\n",
    "    \"\"\"Checks whether input is a binary integer tensor.\"\"\"\n",
    "    if np.issubdtype(X.dtype, int):\n",
    "        if isinstance(X, skt.sptensor):\n",
    "            return (X.vals == 1).all()\n",
    "        else:\n",
    "            return (X <= 1).all() and (X >= 0).all()\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_sparse(X):\n",
    "    M = X.ndim\n",
    "    S = X.size\n",
    "    I = X.nonzero()[0].size\n",
    "    return S > (I + 1) * M\n",
    "\n",
    "\n",
    "def sptensor_from_dense_array(X):\n",
    "    \"\"\"Creates an sptensor from an ndarray or dtensor.\"\"\"\n",
    "    subs = X.nonzero()\n",
    "    vals = X[subs]\n",
    "    return skt.sptensor(subs, vals, shape=X.shape, dtype=X.dtype)\n",
    "\n",
    "\n",
    "def preprocess(X):\n",
    "\n",
    "    if isinstance(X, skt.sptensor):\n",
    "        if not np.issubdtype(X.dtype, int):\n",
    "            X.vals = X.vals.astype(int)\n",
    "            X.dtype = int\n",
    "        return X\n",
    "    else:\n",
    "        if not np.issubdtype(X.dtype, int):\n",
    "            X = X.astype(int)\n",
    "        if is_sparse(X):\n",
    "            return sptensor_from_dense_array(X)\n",
    "        else:\n",
    "            if not isinstance(X, skt.dtensor):\n",
    "                return skt.dtensor(X)\n",
    "\n",
    "\n",
    "def uttkrp(X, m, U):\n",
    "\n",
    "    D, K = U[m].shape\n",
    "    Z = np.rollaxis(X, m, 0)\n",
    "    order = range(X.ndim)\n",
    "    order.remove(m)\n",
    "    Z = np.dot(Z, U[order[-1]])\n",
    "    for mode in reversed(order[:-1]):\n",
    "        Z *= U[mode]\n",
    "        Z = Z.sum(axis=-2)\n",
    "    return Z\n",
    "\n",
    "\n",
    "def sp_uttkrp(vals, subs, m, U):\n",
    "\n",
    "    D, K = U[m].shape\n",
    "    out = np.zeros_like(U[m])\n",
    "    for k in range(K):\n",
    "        tmp = vals.copy()\n",
    "        for mode, matrix in enumerate(U):\n",
    "            if mode == m:\n",
    "                continue\n",
    "            tmp *= matrix[subs[mode], k]\n",
    "        out[:, k] += np.bincount(subs[m],\n",
    "                                 weights=tmp,\n",
    "                                 minlength=D)\n",
    "    return out\n",
    "\n",
    "\n",
    "def parafac(matrices, axis=None):\n",
    "\n",
    "    assert len(matrices) > 1\n",
    "    if axis is None:\n",
    "        N, M = matrices[0].shape\n",
    "        axis_0_all_equal = all([X.shape[0] == N for X in matrices[1:]])\n",
    "        axis_1_all_equal = all([X.shape[1] == M for X in matrices[1:]])\n",
    "        if axis_1_all_equal:\n",
    "            axis = 1\n",
    "        elif axis_0_all_equal:\n",
    "            axis = 0\n",
    "        else:\n",
    "            raise ValueError('Matrices not aligned.')\n",
    "\n",
    "    if len(matrices) == 2:\n",
    "        s = 'za,zb->ab' if axis == 0 else 'az,bz->ab'\n",
    "        return np.einsum(s, matrices[0], matrices[1])\n",
    "    else:\n",
    "        s = 'za,zb->zab' if axis == 0 else 'az,bz->abz'\n",
    "        tmp = np.einsum(s, matrices[0], matrices[1])\n",
    "        curr = 'ab'\n",
    "\n",
    "        letters = list('cdefghijklmnopqrstuv')\n",
    "        for matrix in matrices[2:-1]:\n",
    "            ltr = letters.pop(0)\n",
    "            if axis == 0:\n",
    "                s = 'z%s,z%s->z%s%s' % (curr, ltr, curr, ltr)\n",
    "            else:\n",
    "                s = '%sz,%sz->%s%sz' % (curr, ltr, curr, ltr)\n",
    "            tmp = np.einsum(s, tmp, matrix)\n",
    "            curr += ltr\n",
    "\n",
    "        ltr = letters.pop(0)\n",
    "        if axis == 0:\n",
    "            s = 'z%s,z%s->%s%s' % (curr, ltr, curr, ltr)\n",
    "        else:\n",
    "            s = '%sz,%sz->%s%s' % (curr, ltr, curr, ltr)\n",
    "        return np.einsum(s, tmp, matrices[-1])\n",
    "\n",
    "\n",
    "def serialize_bptf(model, out_dir, num=None, desc=None):\n",
    "    if desc is None:\n",
    "        desc = 'model'\n",
    "    out_dir = Path(out_dir)\n",
    "    assert out_dir.exists()\n",
    "\n",
    "    if num is None:\n",
    "        sleep(rn.random() * 5)\n",
    "        curr_files = out_dir.files('*_%s.npz' % desc)\n",
    "        curr_nums = [int(f.namebase.split('_')[0]) for f in curr_files]\n",
    "        num = max(curr_nums + [0]) + 1\n",
    "\n",
    "    with open(out_dir.joinpath('%d_%s.dat' % (num, desc)), 'wb') as f:\n",
    "        pickle.dump(model.get_params(), f)\n",
    "\n",
    "    out_path = out_dir.joinpath('%d_%s.npz' % (num, desc))\n",
    "    np.savez(out_path,\n",
    "             E_DK_M=model.E_DK_M,\n",
    "             G_DK_M=model.G_DK_M,\n",
    "             gamma_DK_M=model.gamma_DK_M,\n",
    "             delta_DK_M=model.delta_DK_M,\n",
    "             beta_M=model.beta_M)\n",
    "    print (out_path)\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bayesian Poisson tensor factorization with variational inference.\n",
    "\"\"\"\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as rn\n",
    "import scipy.special as sp\n",
    "import sktensor as skt\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "#from utils import *\n",
    "\n",
    "\n",
    "def _gamma_bound_term(pa, pb, qa, qb):\n",
    "    return sp.gammaln(qa) - pa * np.log(qb) + \\\n",
    "        (pa - qa) * sp.psi(qa) + qa * (1 - pb / qb)\n",
    "\n",
    "\n",
    "class BPTF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_modes=4, n_components=100,  max_iter=200, tol=0.0001,\n",
    "                 smoothness=100, verbose=True, alpha=0.1, debug=False):\n",
    "        self.n_modes = n_modes\n",
    "        self.n_components = n_components\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.smoothness = smoothness\n",
    "        self.verbose = verbose\n",
    "        self.debug = debug\n",
    "\n",
    "        self.alpha = alpha                                      # shape hyperparameter\n",
    "        self.beta_M = np.ones(self.n_modes, dtype=float)        # rate hyperparameter (inferred)\n",
    "\n",
    "        self.gamma_DK_M = np.empty(self.n_modes, dtype=object)  # variational shapes\n",
    "        self.delta_DK_M = np.empty(self.n_modes, dtype=object)  # variational rates\n",
    "\n",
    "        self.E_DK_M = np.empty(self.n_modes, dtype=object)      # arithmetic expectations\n",
    "        self.G_DK_M = np.empty(self.n_modes, dtype=object)      # geometric expectations\n",
    "\n",
    "        # Inference cache\n",
    "        self.sumE_MK = np.empty((self.n_modes, self.n_components), dtype=float)\n",
    "        self.nz_recon_I = None\n",
    "\n",
    "    def _reconstruct_nz(self, subs_I_M):\n",
    "        \"\"\"Computes the reconstruction for only non-zero entries.\"\"\"\n",
    "        I = subs_I_M[0].size\n",
    "        K = self.n_components\n",
    "        nz_recon_IK = np.ones((I, K))\n",
    "        for m in range(self.n_modes):\n",
    "            nz_recon_IK *= self.G_DK_M[m][subs_I_M[m], :]\n",
    "        self.nz_recon_I = nz_recon_IK.sum(axis=1)\n",
    "        return self.nz_recon_I\n",
    "\n",
    "    def _test_elbo(self, data):\n",
    "        \"\"\"Copies code from pmf.py.  Used for debugging.\"\"\"\n",
    "        assert data.ndim == 2\n",
    "        if isinstance(data, skt.sptensor):\n",
    "            X = data.toarray()\n",
    "        else:\n",
    "            X = np.array(data)\n",
    "        Et = self.E_DK_M[0]\n",
    "        Eb = self.E_DK_M[1].T\n",
    "        Elogt = np.log(self.G_DK_M[0])\n",
    "        Elogb = np.log(self.G_DK_M[1].T)\n",
    "        gamma_t = self.gamma_DK_M[0]\n",
    "        gamma_b = self.gamma_DK_M[1].T\n",
    "        rho_t = self.delta_DK_M[0]\n",
    "        rho_b = self.delta_DK_M[1].T\n",
    "        Z = np.dot(np.exp(Elogt), np.exp(Elogb))\n",
    "        bound = np.sum(X * np.log(Z) - Et.dot(Eb))\n",
    "        a = self.alpha\n",
    "        c = self.beta_M[0]\n",
    "        bound += _gamma_bound_term(a, a * c, gamma_t, rho_t).sum()\n",
    "        bound += self.n_components * X.shape[0] * a * np.log(c)\n",
    "        bound += _gamma_bound_term(a, a, gamma_b, rho_b).sum()\n",
    "        return bound\n",
    "\n",
    "    def _elbo(self, data, mask=None):\n",
    "        \"\"\"Computes the Evidence Lower Bound (ELBO).\"\"\"\n",
    "\n",
    "        if mask is None:\n",
    "            uttkrp_K = self.sumE_MK.prod(axis=0)\n",
    "        elif isinstance(mask, skt.dtensor):\n",
    "            uttkrp_DK = mask.uttkrp(self.E_DK_M, 0)\n",
    "            uttkrp_K = (self.E_DK_M[0] * uttkrp_DK).sum(axis=0)\n",
    "        elif isinstance(mask, skt.sptensor):\n",
    "            uttkrp_DK = sp_uttkrp(mask.vals, mask.subs, 0, self.E_DK_M)\n",
    "            uttkrp_K = (self.E_DK_M[0] * uttkrp_DK).sum(axis=0)\n",
    "\n",
    "        bound = -uttkrp_K.sum()\n",
    "\n",
    "        if isinstance(data, skt.dtensor):\n",
    "            subs_I_M = data.nonzero()\n",
    "            vals_I = data[subs_I_M]\n",
    "        elif isinstance(data, skt.sptensor):\n",
    "            subs_I_M = data.subs\n",
    "            vals_I = data.vals\n",
    "        nz_recon_I = self._reconstruct_nz(subs_I_M)\n",
    "\n",
    "        bound += (vals_I * np.log(nz_recon_I)).sum()\n",
    "\n",
    "        K = self.n_components\n",
    "        for m in range(self.n_modes):\n",
    "            bound += _gamma_bound_term(pa=self.alpha,\n",
    "                                       pb=self.alpha * self.beta_M[m],\n",
    "                                       qa=self.gamma_DK_M[m],\n",
    "                                       qb=self.delta_DK_M[m]).sum()\n",
    "            bound += K * self.mode_dims[m] * self.alpha * np.log(self.beta_M[m])\n",
    "        return bound\n",
    "\n",
    "    def _init_all_components(self, mode_dims):\n",
    "        assert len(mode_dims) == self.n_modes\n",
    "        self.mode_dims = mode_dims\n",
    "        for m, D in enumerate(mode_dims):\n",
    "            self._init_component(m, D)\n",
    "\n",
    "    def _init_component(self, m, dim):\n",
    "        assert self.mode_dims[m] == dim\n",
    "        K = self.n_components\n",
    "        s = self.smoothness\n",
    "        if not self.debug:\n",
    "            gamma_DK = s * rn.gamma(s, 1. / s, size=(dim, K))\n",
    "            delta_DK = s * rn.gamma(s, 1. / s, size=(dim, K))\n",
    "        else:\n",
    "            gamma_DK = s * np.ones((dim, K))\n",
    "            delta_DK = s * np.ones((dim, K))\n",
    "        self.gamma_DK_M[m] = gamma_DK\n",
    "        self.delta_DK_M[m] = delta_DK\n",
    "        self.E_DK_M[m] = gamma_DK / delta_DK\n",
    "        self.sumE_MK[m, :] = self.E_DK_M[m].sum(axis=0)\n",
    "        self.G_DK_M[m] = np.exp(sp.psi(gamma_DK) - np.log(delta_DK))\n",
    "        if m == 0 or not self.debug:\n",
    "            self.beta_M[m] = 1. / self.E_DK_M[m].mean()\n",
    "\n",
    "    def _check_component(self, m):\n",
    "        assert np.isfinite(self.E_DK_M[m]).all()\n",
    "        assert np.isfinite(self.G_DK_M[m]).all()\n",
    "        assert np.isfinite(self.gamma_DK_M[m]).all()\n",
    "        assert np.isfinite(self.delta_DK_M[m]).all()\n",
    "\n",
    "    def _update_gamma(self, m, data):\n",
    "        if isinstance(data, skt.dtensor):\n",
    "            tmp = data.astype(float)\n",
    "            subs_I_M = data.nonzero()\n",
    "            tmp[subs_I_M] /= self._reconstruct_nz(subs_I_M)\n",
    "            uttkrp_DK = tmp.uttkrp(self.G_DK_M, m)\n",
    "\n",
    "        elif isinstance(data, skt.sptensor):\n",
    "            tmp = data.vals / self._reconstruct_nz(data.subs)\n",
    "            uttkrp_DK = sp_uttkrp(tmp, data.subs, m, self.G_DK_M)\n",
    "\n",
    "        self.gamma_DK_M[m][:, :] = self.alpha + self.G_DK_M[m] * uttkrp_DK\n",
    "\n",
    "    def _update_delta(self, m, mask=None):\n",
    "        if mask is None:\n",
    "            self.sumE_MK[m, :] = 1.\n",
    "            uttkrp_DK = self.sumE_MK.prod(axis=0)\n",
    "        else:\n",
    "            uttkrp_DK = mask.uttkrp(self.E_DK_M, m)\n",
    "        self.delta_DK_M[m][:, :] = self.alpha * self.beta_M[m] + uttkrp_DK\n",
    "\n",
    "    def _update_cache(self, m):\n",
    "        gamma_DK = self.gamma_DK_M[m]\n",
    "        delta_DK = self.delta_DK_M[m]\n",
    "        self.E_DK_M[m] = gamma_DK / delta_DK\n",
    "        self.sumE_MK[m, :] = self.E_DK_M[m].sum(axis=0)\n",
    "        self.G_DK_M[m] = np.exp(sp.psi(gamma_DK) - np.log(delta_DK))\n",
    "\n",
    "    def _update_beta(self, m):\n",
    "        self.beta_M[m] = 1. / self.E_DK_M[m].mean()\n",
    "\n",
    "    def _update(self, data, mask=None, modes=None):\n",
    "        if modes is not None:\n",
    "            modes = list(set(modes))\n",
    "        else:\n",
    "            modes = range(self.n_modes)\n",
    "        assert all(m in range(self.n_modes) for m in modes)\n",
    "\n",
    "        for m in range(self.n_modes):\n",
    "            if m not in modes:\n",
    "                self._clamp_component(m)\n",
    "\n",
    "        if self.debug:\n",
    "            curr_elbo = self._test_elbo(data)\n",
    "        else:\n",
    "            curr_elbo = self._elbo(data, mask=mask)\n",
    "        if self.verbose:\n",
    "            print ('ITERATION %d:\\t'\\\n",
    "                  'Time: %f\\t'\\\n",
    "                  'Objective: %.2f\\t'\\\n",
    "                  'Change: %.5e\\t'\\\n",
    "                % (0, 0.0, curr_elbo, np.nan))\n",
    "\n",
    "        for itn in range(self.max_iter):\n",
    "            s = time.time()\n",
    "            for m in modes:\n",
    "                self._update_gamma(m, data)\n",
    "                self._update_delta(m, mask)\n",
    "                self._update_cache(m)\n",
    "                if m == 0 or not self.debug:\n",
    "                    self._update_beta(m)  # must come after cache update!\n",
    "                self._check_component(m)\n",
    "            if self.debug:\n",
    "                bound = self._test_elbo(data)\n",
    "            else:\n",
    "                bound = self._elbo(data, mask=mask)\n",
    "            delta = (bound - curr_elbo) / abs(curr_elbo)\n",
    "            e = time.time() - s\n",
    "            if self.verbose:\n",
    "                print ('ITERATION %d:\\t'\\\n",
    "                      'Time: %f\\t'\\\n",
    "                      'Objective: %.2f\\t'\\\n",
    "                      'Change: %.5e\\t'\\\n",
    "                      % (itn+1, e, bound, delta))\n",
    "            if not (delta >= 0.0):\n",
    "                raise Exception('\\n\\nNegative ELBO improvement: %e\\n' % delta)\n",
    "            curr_elbo = bound\n",
    "            if delta < self.tol:\n",
    "                break\n",
    "\n",
    "    def set_component(self, m, E_DK, G_DK, gamma_DK, delta_DK):\n",
    "        assert E_DK.shape[1] == self.n_components\n",
    "        self.E_DK_M[m] = E_DK.copy()\n",
    "        self.sumE_MK[m, :] = E_DK.sum(axis=0)\n",
    "        self.G_DK_M[m] = G_DK.copy()\n",
    "        self.gamma_DK_M[m] = gamma_DK.copy()\n",
    "        self.delta_DK_M[m] = delta_DK.copy()\n",
    "        self.beta_M[m] = 1. / E_DK.mean()\n",
    "\n",
    "    def _clamp_component(self, m, version='geometric'):\n",
    "        \"\"\"Make a component a constant.\n",
    "        This amounts to setting the expectations under the\n",
    "        Q-distribution to be equal to a single point estimate.\n",
    "        \"\"\"\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "        if version == 'geometric':\n",
    "            self.E_DK_M[m][:, :] = self.G_DK_M[m]\n",
    "        else:\n",
    "            self.G_DK_M[m][:, :] = self.E_DK_M[m]\n",
    "        self.sumE_MK[m, :] = self.E_DK_M[m].sum(axis=0)\n",
    "        self.beta_M[m] = 1. / self.E_DK_M[m].mean()\n",
    "\n",
    "    def set_component_like(self, m, model, subs_D=None):\n",
    "        assert model.n_modes == self.n_modes\n",
    "        assert model.n_components == self.n_components\n",
    "        D = model.E_DK_M[m].shape[0]\n",
    "        if subs_D is None:\n",
    "            subs_D = np.arange(D)\n",
    "        assert min(subs_D) >= 0 and max(subs_D) < D\n",
    "        E_DK = model.E_DK_M[m][subs_D, :].copy()\n",
    "        G_DK = model.G_DK_M[m][subs_D, :].copy()\n",
    "        gamma_DK = model.gamma_DK_M[m][subs_D, :].copy()\n",
    "        delta_DK = model.delta_DK_M[m][subs_D, :].copy()\n",
    "        self.set_component(m, E_DK, G_DK, gamma_DK, delta_DK)\n",
    "\n",
    "    def fit(self, data, mask=None):\n",
    "        assert data.ndim == self.n_modes\n",
    "        data = preprocess(data)\n",
    "        if mask is not None:\n",
    "            mask = preprocess(mask)\n",
    "            assert data.shape == mask.shape\n",
    "            assert is_binary(mask)\n",
    "            assert np.issubdtype(mask.dtype, int)\n",
    "        self._init_all_components(data.shape)\n",
    "        self._update(data, mask=mask)\n",
    "        return self\n",
    "\n",
    "    def transform(self, modes, data, mask=None, version='geometric'):\n",
    "        \"\"\"Transform new data given a pre-trained model.\"\"\"\n",
    "        assert all(m in range(self.n_modes) for m in modes)\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "\n",
    "        assert data.ndim == self.n_modes\n",
    "        data = preprocess(data)\n",
    "        if mask is not None:\n",
    "            mask = preprocess(mask)\n",
    "            assert data.shape == mask.shape\n",
    "            assert is_binary(mask)\n",
    "            assert np.issubdtype(mask.dtype, int)\n",
    "        self.mode_dims = data.shape\n",
    "        for m, D in enumerate(self.mode_dims):\n",
    "            if m not in modes:\n",
    "                if self.E_DK_M[m].shape[0] != D:\n",
    "                    raise ValueError('Pre-trained components dont match new data.')\n",
    "            else:\n",
    "                self._init_component(m, D)\n",
    "        self._update(data, mask=mask, modes=modes)\n",
    "\n",
    "        if version == 'geometric':\n",
    "            return [self.G_DK_M[m] for m in modes]\n",
    "        elif version == 'arithmetic':\n",
    "            return [self.E_DK_M[m] for m in modes]\n",
    "\n",
    "    def fit_transform(self, modes, data, mask=None, version='geometric'):\n",
    "        assert all(m in range(self.n_modes) for m in modes)\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "\n",
    "        self.fit(data, mask=mask)\n",
    "\n",
    "        if version == 'geometric':\n",
    "            return [self.G_DK_M[m] for m in modes]\n",
    "        elif version == 'arithmetic':\n",
    "            return [self.E_DK_M[m] for m in modes]\n",
    "\n",
    "    def reconstruct(self, mask=None, version='geometric', drop_diag=False):\n",
    "        \"\"\"Reconstruct data using point estimates of latent factors.\n",
    "        Currently supported only up to 5-way tensors.\n",
    "        \"\"\"\n",
    "        assert (version == 'geometric') or (version == 'arithmetic')\n",
    "        if version == 'geometric':\n",
    "            tmp = [G_DK.copy() for G_DK in self.G_DK_M]\n",
    "        elif version == 'arithmetic':\n",
    "            tmp = [E_DK.copy() for E_DK in self.E_DK_M]\n",
    "\n",
    "        Y_pred = parafac(tmp)\n",
    "        if drop_diag:\n",
    "            diag_idx = np.identity(Y_pred.shape[0]).astype(bool)\n",
    "            Y_pred[diag_idx] = 0\n",
    "        return Y_pred\n",
    "\n",
    "\n",
    "def main():\n",
    "    p = ArgumentParser()\n",
    "    p.add_argument('-d', '--data', type=Path, required=True)\n",
    "    p.add_argument('-o', '--out', type=Path, required=True)\n",
    "    p.add_argument('-m', '--mask', type=Path, default=None)\n",
    "    p.add_argument('-k', '--n_components', type=int, required=True)\n",
    "    p.add_argument('-n', '--max_iter', type=int, default=200)\n",
    "    p.add_argument('-t', '--tol', type=float, default=1e-4)\n",
    "    p.add_argument('-s', '--smoothness', type=int, default=100)\n",
    "    p.add_argument('-a', '--alpha', type=float, default=0.1)\n",
    "    p.add_argument('-v', '--verbose', action=\"store_true\", default=False)\n",
    "    p.add_argument('--debug', action=\"store_true\", default=False)\n",
    "    args = p.parse_args()\n",
    "\n",
    "    args.out.makedirs_p()\n",
    "    assert args.data.exists() and args.out.exists()\n",
    "    if args.data.ext == '.npz':\n",
    "        data_dict = np.load(args.data)\n",
    "        if 'data' in data_dict.files:\n",
    "            data = data_dict['data']\n",
    "        elif 'Y' in data_dict.files:\n",
    "            data = data_dict['Y']\n",
    "        if data.dtype == 'object':\n",
    "            assert data.size == 1\n",
    "            data = data[0]\n",
    "    else:\n",
    "        data = np.load(args.data)\n",
    "\n",
    "    valid_types = [np.ndarray, skt.dtensor, skt.sptensor]\n",
    "    assert any(isinstance(data, vt) for vt in valid_types)\n",
    "\n",
    "    mask = None\n",
    "    if args.mask is not None:\n",
    "        if args.mask.ext == '.npz':\n",
    "            mask = np.load(args.mask)['mask']\n",
    "            if mask.dtype == 'object':\n",
    "                assert mask.size == 1\n",
    "                mask = mask[0]\n",
    "        else:\n",
    "            mask = np.load(args.mask)\n",
    "\n",
    "        assert any(isinstance(mask, vt) for vt in valid_types)\n",
    "        assert mask.shape == data.shape\n",
    "\n",
    "    bptf = BPTF(n_modes=data.ndim,\n",
    "                n_components=args.n_components,\n",
    "                max_iter=args.max_iter,\n",
    "                tol=args.tol,\n",
    "                smoothness=args.smoothness,\n",
    "                verbose=args.verbose,\n",
    "                alpha=args.alpha,\n",
    "                debug=args.debug)\n",
    "\n",
    "    bptf.fit(data, mask=mask)\n",
    "    serialize_bptf(bptf, args.out, num=None, desc='trained_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rn\n",
    "import scipy.stats as st\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "#from bptf import BPTF\n",
    "#from utils import parafac\n",
    "\n",
    "\n",
    "def generate(shp=(300, 300, 300, 300), K=5, alpha=0.1, beta=0.1):\n",
    "\n",
    "    Theta_DK_M = [rn.gamma(alpha, 1./beta, size=(D, K)) for D in shp]\n",
    "    Mu = parafac(Theta_DK_M)\n",
    "    assert Mu.shape == shp\n",
    "    Y = rn.poisson(Mu)\n",
    "    return Mu, Y\n",
    "\n",
    "\n",
    "def corrupt(Y, p=0.05):\n",
    "    \"\"\"Corrupt a count tensor with anomalies.\n",
    "    The corruption noise model is:\n",
    "        corrupt(y) = y * g, where g ~ Gamma(10, 2)\n",
    "    PARAMS:\n",
    "    p -- (float) proportion of tensor entries to corrupt\n",
    "    RETURNS:\n",
    "    out -- (np.ndarray) corrupted count tensor\n",
    "    mask -- (np.ndarray) boolean array, same shape as count tensor\n",
    "                         True means that entry was corrupted.\n",
    "    \"\"\"\n",
    "    out = Y.copy()\n",
    "    mask = (rn.random(size=out.shape) < p).astype(bool)\n",
    "    out[mask] = rn.poisson(out[mask] * rn.gamma(10., 2., size=out[mask].shape))\n",
    "    return out, mask\n",
    "\n",
    "\n",
    "def detect(Y, K=5, alpha=0.1, thresh=1e-5):\n",
    "\n",
    "    bptf = BPTF(n_modes=Y.ndim,\n",
    "                n_components=K,\n",
    "                max_iter=100,\n",
    "                tol=1e-4,\n",
    "                smoothness=100,\n",
    "                verbose=False,\n",
    "                alpha=alpha,\n",
    "                debug=False)\n",
    "    bptf.fit(Y)\n",
    "    Mu = bptf.reconstruct()\n",
    "\n",
    "    return st.poisson.pmf(Y, Mu) < thresh\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Generate true Poisson rates and data count tensor\n",
    "    K = 5\n",
    "    alpha = 0.1\n",
    "    Mu, Y = generate(K=K, alpha=alpha)\n",
    "\n",
    "    # Obtain the corrupted count tensor\n",
    "    p = 0.01\n",
    "    corrupted_Y, mask = corrupt(Y, p=p)\n",
    "    assert corrupted_Y.shape == Y.shape\n",
    "    assert mask.shape == Y.shape\n",
    "    print ('%d entries corrupted' % (mask.sum()))\n",
    "\n",
    "    thresh = 1e-5\n",
    "\n",
    "    # Calculate an upper bound on the results (using the true underlying Mu)\n",
    "    print ('\\n----Upper bound on results (using true Mu)----')\n",
    "    detected = st.poisson.pmf(corrupted_Y, Mu) < thresh\n",
    "    assert detected.shape == Y.shape\n",
    "    print ('precision: %f' % precision_score(mask.ravel(), detected.ravel()))\n",
    "    print ('recall: %f' % recall_score(mask.ravel(), detected.ravel()))\n",
    "    print ('f1: %f' % f1_score(mask.ravel(), detected.ravel()))\n",
    "\n",
    "    # Calculate results using BPTF\n",
    "    print ('\\n----Results (using BPTF)----')\n",
    "    detected = detect(corrupted_Y, K=K, alpha=alpha, thresh=thresh)\n",
    "    assert detected.shape == Y.shape\n",
    "    print ('precision: %f' % precision_score(mask.ravel(), detected.ravel()))\n",
    "    print ('recall: %f' % recall_score(mask.ravel(), detected.ravel()))\n",
    "    print ('f1: %f' % f1_score(mask.ravel(), detected.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
